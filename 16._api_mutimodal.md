**API Multimodal Live**

A API Multimodal Live permite interações de voz e vídeo bidirecionais de baixa latência com o Gemini. Com essa API, é possível oferecer aos usuários finais uma experiência de conversas por voz naturais e semelhantes às humanas, além de permitir que interrompam as respostas do modelo usando comandos de voz. O modelo pode processar entradas de texto, áudio e vídeo, fornecendo saídas de texto e áudio.

**Recursos Principais**

- **Multimodalidade**: O modelo é capaz de ver, ouvir e falar, permitindo uma interação mais rica e natural.

- **Interação em tempo real com baixa latência**: Oferece respostas rápidas, essenciais para conversas naturais e dinâmicas.

- **Memória de sessão**: O modelo mantém memória de todas as interações dentro de uma única sessão, permitindo relembrar informações previamente vistas ou ouvidas.

- **Suporte a chamadas de função, execução de código e uso de pesquisa como ferramenta**: Facilita a integração com serviços externos e fontes de dados, ampliando as capacidades do modelo.

- **Detecção automática de atividade de voz (VAD)**: O modelo consegue identificar com precisão quando o usuário começa e termina de falar, permitindo interações mais naturais e a possibilidade de interromper o modelo a qualquer momento.

**Como Começar**

A API Multimodal Live é uma API com estado que utiliza WebSockets. A seguir, um exemplo de como utilizá-la para gerar texto a partir de texto utilizando Python 3.9 ou superior:

1. **Instalar a biblioteca da API Gemini**:

   ```bash
   pip install google-genai
   ```


2. **Importar as dependências**:

   ```python
   from google import genai
   import asyncio
   ```


3. **Configurar o cliente e a sessão**:

   ```python
   client = genai.Client(api_key="SUA_CHAVE_DE_API", http_options={'api_version': 'v1alpha'})
   model_id = "gemini-2.0-flash-exp"
   config = {"response_modalities": ["TEXT"]}
   ```


4. **Função principal para enviar e receber mensagens**:

   ```python
   async def main():
       async with client.aio.live.connect(model=model_id, config=config) as session:
           while True:
               message = input("Usuário> ")
               if message.lower() == "sair":
                   break
               await session.send(input=message, end_of_turn=True)
               async for response in session.receive():
                   if response.text is None:
                       continue
                   print(response.text, end="")
   ```


5. **Executar a função principal**:

   ```python
   if __name__ == "__main__":
       asyncio.run(main())
   ```


**Guia de Integração**

Para integrar a API Multimodal Live, é estabelecida uma conexão WebSocket entre o cliente e o servidor Gemini, criando uma sessão. Após a conexão, o cliente pode trocar mensagens com o servidor para:

- Enviar texto, áudio ou vídeo para o servidor Gemini.

- Receber áudio, texto ou solicitações de chamada de função do servidor Gemini.

A configuração da sessão é enviada na primeira mensagem após a conexão e inclui detalhes como o modelo a ser utilizado, parâmetros de geração, instruções do sistema e ferramentas disponíveis. Para mais detalhes sobre as opções de configuração, consulte a documentação oficial.


